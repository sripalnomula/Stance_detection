# -*- coding: utf-8 -*-
"""stance.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SonQlKEXrhm0a-j14KxUeciqi4py259j
"""

import pandas as pd
import numpy as np
train = pd.read_csv('train_merged.csv', encoding ='latin-1')
test = pd.read_csv('test_merged.csv', encoding = 'latin-1')
train.head()

sample = train.head(1000).sample(10)
sample

train.info()

df = train.copy()
df.head()

df.isnull().sum()

df.info()

df.shape

df = df.drop_duplicates()
df.shape

"""## Observation: we can observe that there are approx 400 duplicate rows."""

# let us Check the summary statistics(5- point summary) of the dataset
df.describe()

# Checking the distribution of the 'class' column i.e., true or fake
df['Stance'].value_counts()

import matplotlib.pyplot as plt
# Plotting the distribution of the each stance in the  given dataset. 
plt.figure(figsize=(8, 6))
df['Stance'].value_counts().plot(kind='bar')
plt.title("Distribution of 'Stance' column")
plt.xlabel("Stance")
plt.ylabel("Count")
plt.show()

# import seaborn as sns
# fig, ax = plt.subplots(1,2, figsize=(19, 5))
# ax = sns.countplot(x = df['Stance'],ax=ax[0])
# plt.title('Distribution of stance in articles')
# ax.set(xticklabels=['Unrelated', 'discuss', 'agree', 'disagree'])
# plt.xlabel('News Type')
# plt.ylabel('Number of News')
# plt.pie(df["Stance"].value_counts().values,explode=[0,0],labels=df["Stance"].value_counts().index, autopct='%1.1f%%')
# fig.show()

import seaborn as sns

fig, ax = plt.subplots(1, 2, figsize=(19, 5))

sns.countplot(x=df['Stance'], ax=ax[0])
ax[0].set_title('Distribution of Stance in Articles')
ax[0].set(xticklabels=['Unrelated', 'Discuss', 'Agree', 'Disagree'])
ax[0].set_xlabel('Stance Type')
ax[0].set_ylabel('Number of Articles')

ax[1].pie(df["Stance"].value_counts().values, explode=[0, 0, 0, 0.1], 
          labels=df["Stance"].value_counts().index, autopct='%1.1f%%')
ax[1].set_title('Distribution of Stance in Articles')

#here is the comparition of articles with word count vs class(True or Fake)
df_unrelated = df[df['Stance'] == 'unrelated']
df_Discuss = df[df['Stance'] == 'discuss']
df_agree = df[df['Stance'] == 'agree']
df_Disagree = df[df['Stance'] == 'disagree']

word_count_unrelated = df_unrelated['articleBody'].apply(lambda x: len(x.split()))
word_count_discuss = df_Discuss['articleBody'].apply(lambda x: len(x.split()))
word_count_agree = df_agree['articleBody'].apply(lambda x: len(x.split()))
word_count_disagree = df_Disagree['articleBody'].apply(lambda x: len(x.split()))

print("Average word count for Unrelated Stance: ", word_count_unrelated.mean())
print("Average word count for Discuss Stance: ", word_count_discuss.mean())
print("Average word count for Agree Stance: ", word_count_agree.mean())
print("Average word count for Disagree Stance: ", word_count_disagree.mean())

plt.boxplot([word_count_unrelated, word_count_discuss, word_count_agree, word_count_disagree], labels=['unrelated', 'discuss','agree','disagree'])
plt.title('Comparison of Word Counts in Body of Article for each stance')
plt.ylabel('Word Count in Body of Article')
plt.show()

headline_word_count_unrelated = df_unrelated['Headline'].apply(lambda x: len(x.split()))
headline_word_count_discuss = df_Discuss['Headline'].apply(lambda x: len(x.split()))
headline_word_count_agree = df_agree['Headline'].apply(lambda x: len(x.split()))
headline_word_count_disagree = df_Disagree['Headline'].apply(lambda x: len(x.split()))
print("Average word count for Unrelated Stance: ", headline_word_count_unrelated.mean())
print("Average word count for Discuss Stance: ", headline_word_count_discuss.mean())
print("Average word count for Agree Stance: ", headline_word_count_agree.mean())
print("Average word count for Disagree Stance: ", headline_word_count_disagree.mean())
plt.boxplot([headline_word_count_unrelated, headline_word_count_discuss, headline_word_count_agree, headline_word_count_disagree], labels=['unrelated', 'discuss','agree','disagree'])
plt.title('Comparison of Word Counts in Headline  for each stance')
plt.ylabel('Word Count in Headline of Article')

plt.figure(figsize=(8, 6))
plt.scatter(df['Headline'].str.len(), df['articleBody'].str.len(),color="green")
plt.title("Relationship between Headline and articleBody length")
plt.xlabel("Headline length (in characters)")
plt.ylabel("articleBody length (in characters)")

from collections import Counter

def plot_top_words(df, label):
    text = ' '.join(df[df['Stance']==label]['articleBody'].astype(str).tolist())
    word_freq = Counter(text.split()).most_common(10)
    words = [pair[0] for pair in word_freq]
    counts = [pair[1] for pair in word_freq]
    plt.figure(figsize=(8, 6))
    plt.bar(words, counts)
    plt.title(f"Top 10 most frequent words in {label} news")
    plt.xlabel("Word")
    plt.ylabel("Count")
    plt.show()

plot_top_words(df, 'unrelated')
plot_top_words(df, 'discuss')
plot_top_words(df, 'agree')
plot_top_words(df, 'disagree')

df['Headline_len'] = df['articleBody'].str.len()
df['num_exclamations'] = df['articleBody'].str.count('!')
df['Body_len'] = df['Headline'].str.len()
#print(df.head())
corr_matrix = df[['Headline_len', 'Body_len', 'num_exclamations']].corr()
plt.figure(figsize=(8, 6))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')
plt.title('Correlation Matrix')
plt.show()





























